{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### GBR & XGBR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I merge the hpg relavant dataset and air relavant dataset, there is a lot of missing data since the store id is not match completely. However, the NN could figure out the missing data which is data mining in the data which include the missing data directly. Normally, the system set the null number as -1 to present this value is not exist. So, in the data preprocessing part, i refill the missing data to -1. Then the NN could handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from datetime import datetime\n",
    "from xgboost import XGBRegressor\n",
    "from keras.layers import Embedding, Input, Dense\n",
    "from keras.models import Model\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "train=pd.read_csv('E:/Foundations of Data Science/Referral/Forecast customer/Data/PreparedData/train.csv')\n",
    "test=pd.read_csv('E:/Foundations of Data Science/Referral/Forecast customer/Data/PreparedData/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred)**0.5\n",
    "\n",
    "def plot_actual_predicted(actual, predicted):\n",
    "    print('RMSE: ', RMSLE(actual, predicted))\n",
    "    tmp = pd.DataFrame({'actual': actual, 'predicted': predicted}).sort_values(['actual'])\n",
    "    plt.scatter(range(tmp.shape[0]), tmp['predicted'], color='green')\n",
    "    plt.scatter(range(tmp.shape[0]), tmp['actual'], color='blue')\n",
    "    plt.show()\n",
    "    del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the Train and test data prepared for NN\n",
    "value_col = ['holiday_flg','min_visitors','mean_visitors','median_visitors','max_visitors','count_observations',\n",
    "'rs1_x','rv1_x','rs2_x','rv2_x','rs1_y','rv1_y','rs2_y','rv2_y','total_reserv_sum','total_reserv_mean',\n",
    "'total_reserv_dt_diff_mean','date_int','var_max_lat','var_max_long','lon_plus_lat']\n",
    "\n",
    "nn_col = value_col + ['dow', 'year', 'month', 'air_store_id2', 'air_area_name', 'air_genre_name',\n",
    "'air_area_name0', 'air_area_name1', 'air_area_name2', 'air_area_name3', 'air_area_name4',\n",
    "'air_area_name5', 'air_area_name6', 'air_genre_name0', 'air_genre_name1',\n",
    "'air_genre_name2', 'air_genre_name3', 'air_genre_name4']\n",
    "\n",
    "X = train.copy()\n",
    "X_test = test[nn_col].copy()\n",
    "\n",
    "value_scaler = preprocessing.MinMaxScaler()\n",
    "for vcol in value_col:\n",
    "    X[vcol] = value_scaler.fit_transform(X[vcol].values.astype(np.float64).reshape(-1, 1))\n",
    "    X_test[vcol] = value_scaler.transform(X_test[vcol].values.astype(np.float64).reshape(-1, 1))\n",
    "\n",
    "X_train = list(X[nn_col].T.as_matrix())\n",
    "Y_train = X['visitors'].values\n",
    "nn_train = [X_train, Y_train]\n",
    "nn_test = [list(X_test[nn_col].T.as_matrix())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1 trained\n"
     ]
    }
   ],
   "source": [
    "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date','visitors']]\n",
    "model1 = ensemble.GradientBoostingRegressor(learning_rate=0.2, random_state=3,\n",
    "                    n_estimators=180, subsample=0.78, max_depth=10)\n",
    "# model2 = neighbors.KNeighborsRegressor(n_jobs=-1, n_neighbors=4)\n",
    "# model2 = ensemble.RandomForestRegressor(n_estimators=13, random_state=3, max_depth=18,\n",
    "#                                         min_weight_fraction_leaf=0.0002)\n",
    "model3 = XGBRegressor(learning_rate=0.2, random_state=3, n_estimators=330, subsample=0.8, \n",
    "                      colsample_bytree=0.8, max_depth=10)\n",
    "\n",
    "model1.fit(train[col], train['visitors'].values)\n",
    "print(\"Model1 trained\")\n",
    "\n",
    "model3.fit(train[col], train['visitors'].values)\n",
    "print(\"Model3 trained\")\n",
    "\n",
    "\n",
    "preds1 = model1.predict(train[col])\n",
    "preds3 = model3.predict(train[col])\n",
    "\n",
    "actual_output = train['visitors'].values\n",
    "print('GradientBoostingRegressor:')\n",
    "plot_actual_predicted(actual_output, preds1)\n",
    "print('XGBRegressor:')\n",
    "plot_actual_predicted(actual_output, preds3)\n",
    "\n",
    "preds1 = model1.predict(test[col])\n",
    "preds3 = model3.predict(test[col])\n",
    "\n",
    "test['visitors'] =preds3\n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower=0.)\n",
    "sub1 = test[['id','visitors']].copy()\n",
    "print(\"Model predictions done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
